{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Aron\n",
    "Name : MWT(Mongolian Word Tokenizer)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, string\n",
    "from os import path\n",
    "from progressbar import ProgressBar\n",
    "from icu import UnicodeString, BreakIterator, Locale\n",
    "from collections import defaultdict\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def containsMongolianChar(word):\n",
    "    for ch in word:\n",
    "        if 0x1800 < ord(ch) < 0x18ff:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'180B,180C,180D,180E'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MONGOLIAN_PUNCTUATIONS = \"\".join([chr(w) for w in range(0x1800,0x180a)])\n",
    "MONGOLIAN_DIGISTS = \"\".join([chr(w) for w in range(0x1810,0x181a)])\n",
    "MONGOLIAN_CONTROL_CHAR = \"\".join([chr(w) for w in range(0x180b,0x180f)])+\"\\u200d\"\n",
    "# CodeStr(MONGOLIAN_CONTROL_CHAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRIP_CHARS = string.ascii_letters \\\n",
    "            + string.whitespace \\\n",
    "            + string.punctuation \\\n",
    "            + string.digits \\\n",
    "            + MONGOLIAN_PUNCTUATIONS \\\n",
    "            + MONGOLIAN_DIGISTS \\\n",
    "            + \"\\u3008\\u00b7\\u00a7\\u00ab<>\\u300a\\u3000\\u300b\\u1804\\u1802\\u1803\\u0028\\u0029\\ufe15\\ufe16\\u7267\\u6B4C\\u2014\\u00a0\\u0020\\u1802\\u1803\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitStemAndSuffix(word):\n",
    "    \"\"\"\n",
    "    split word to stem and suffixes\n",
    "    \"\"\"\n",
    "    ls = word.split(\"\\u202f\")\n",
    "    if len(ls) > 1:\n",
    "        return ls[0], [\"\\u202f\" + s for s in ls[1:]]\n",
    "    else:\n",
    "        return None, None\n",
    "# stem, suffix = splitStemAndSuffix(\"asdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CodeStr(text):\n",
    "    ls = []\n",
    "    for ch in text:\n",
    "        ls.append(ord(ch))\n",
    "    return \",\".join([\"%04X\"%(c) for c in ls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_line_with_icu(line):\n",
    "    boundary = BreakIterator.createWordInstance(Locale.getUS())\n",
    "    # text = \"dasdf asdf asd f\"\n",
    "    boundary.setText(line)\n",
    "    \n",
    "    word_list = []\n",
    "    \n",
    "    start = boundary.first()\n",
    "#         ls =[]\n",
    "    for end in boundary:\n",
    "        word = line[start:end ]\n",
    "        word = word.strip(STRIP_CHARS)\n",
    "        if (not word.strip() == \"\") and (not word.strip(MONGOLIAN_CONTROL_CHAR) == \"\") and containsMongolianChar(word) :\n",
    "            word_list.append(word)\n",
    "        start = end\n",
    "    return word_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_line_with_py(line):\n",
    "    \n",
    "    word_list_ = line.split(\" \")\n",
    "    word_list = []\n",
    "    for word in word_list_:\n",
    "        word = word.strip(STRIP_CHARS)\n",
    "        if not word.strip() == \"\" and containsMongolianChar(word):\n",
    "            word_list.append(word)\n",
    "    return word_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@click.command()\n",
    "@click.option('--input-file', \"-f\", type=click.Path(exists=True), help='Input file' ,required=True)\n",
    "@click.option('--output-file', \"-o\", type=click.Path(), help='Output file', required=True)\n",
    "# @click.option('--splitter', \"-s\", type=click.Path(), help='Output file', required=True)\n",
    "# @click.option('--with-icu-break', \"-i\", type=click.Path(), help='Output file', required=True)\n",
    "# @click.option('--with-python', \"-p\", type=click.Path(), help='Output file', required=True)\n",
    "# @click.option('--with-icu', \"-n\", type=click.Path(), help='Output file', required=True)\n",
    "def main(input_file, output_file):\n",
    "#     click.echo(input_file)\n",
    "#     click.echo(output_file)\n",
    "    \n",
    "        \n",
    "    \n",
    "    word_dict = defaultdict(lambda :0)\n",
    "    p = ProgressBar()\n",
    "#     r = opendb()\n",
    "    outfile_path =\"\"\n",
    "    \n",
    "    \n",
    "    split_line = split_line_with_icu\n",
    "        \n",
    "    \n",
    "    \n",
    "    with open(input_file, \"r\") as in_file:\n",
    "        for i, line in enumerate(p(in_file)):\n",
    "            p.update(i + 1)\n",
    "            line = line.strip()\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            for word in split_line(line):\n",
    "                ## word_dict[word] += 1\n",
    "                stem, suffix = splitStemAndSuffix(word)\n",
    "                if stem is None:\n",
    "                    word_dict[word] += 1\n",
    "                else:\n",
    "                    if (not stem.strip() == \"\") and containsMongolianChar(stem):\n",
    "                        word_dict[stem] += 1\n",
    "                    for suf in suffix:\n",
    "                        word_dict[suf] += 1\n",
    "    #                 ss = r.get(word)\n",
    "    #                 if ss is None:\n",
    "    #                     r.set(word, str(i))\n",
    "    #                 else:\n",
    "    #                     text = ss.decode(\"utf-8\")\n",
    "    #         #                 print(text)\n",
    "    #                     ls = text.split(\",\")\n",
    "    #                     ls.append(str(i))\n",
    "    #                     r.set(word, \",\".join(set(ls)))         \n",
    "    with open(output_file, \"w\") as out_file:\n",
    "        for word, count in sorted(word_dict.items(), key =lambda a: a[0]):\n",
    "            print(word, CodeStr(word), count, file = out_file)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    main()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датун ᠢ Датун \n"
     ]
    }
   ],
   "source": [
    "text = \"Датун ᠢ Датун \"\n",
    "boundary = BreakIterator.createWordInstance(Locale('mn_CN'))\n",
    "boundary.setText(text)\n",
    "start = boundary.first()\n",
    "for end in boundary:\n",
    "    print(text[start:end])\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Датун\\u202fᠢ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_line_icu(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'モンゴル語 (中国)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locale = Locale('mn_CN')\n",
    "locale.getDisplayName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/aron/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0414,0430,0442,0443,043D,202F,1822,0414,0430,0442,0443,043D,202F\n",
      "Датун 0414,0430,0442,0443,043D\n",
      "ᠢДатун 1822,0414,0430,0442,0443,043D\n"
     ]
    }
   ],
   "source": [
    "text = \"Датун ᠢДатун \"\n",
    "print(CodeStr(text))\n",
    "wordlist = word_tokenize(text)\n",
    "for w in wordlist:\n",
    "    print(w, CodeStr(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
